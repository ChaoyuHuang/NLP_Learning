{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATED BY HCY 20200728 23:28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:27:22.627209Z",
     "start_time": "2020-08-06T12:27:16.491245Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.vocab import Vocab\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:27:32.073350Z",
     "start_time": "2020-08-06T12:27:22.628098Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:27:32.078238Z",
     "start_time": "2020-08-06T12:27:32.074249Z"
    }
   },
   "outputs": [],
   "source": [
    "matched_sets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:30:54.803282Z",
     "start_time": "2020-08-06T12:30:54.799292Z"
    }
   },
   "outputs": [],
   "source": [
    "pattern = [{\"LOWER\": \"facebook\"}, {\"LEMMA\": \"be\"}, {\"POS\": \"ADV\", \"OP\": \"*\"}, {\"POS\":\"ADJ\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:31:01.032478Z",
     "start_time": "2020-08-06T12:31:01.027491Z"
    }
   },
   "outputs": [],
   "source": [
    "def callback_method_fb(matcher, doc, i, matches):\n",
    "    matched_id, start, end = matches[i]\n",
    "    span = doc[start:end]\n",
    "    sent = span.sent\n",
    "    match_ents = [{'start': span.start_char - sent.start_char,\n",
    "                   'end': span.end_char - sent.start_char,\n",
    "                   'label': 'MATCH'}]\n",
    "    matched_sets.append({'text': sent.text, 'ents': match_ents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:31:18.084471Z",
     "start_time": "2020-08-06T12:31:17.983394Z"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"I'd say that Facebook is evil. - Facebook is pretty cool, right?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:31:20.211667Z",
     "start_time": "2020-08-06T12:31:20.207664Z"
    }
   },
   "outputs": [],
   "source": [
    "matcher.add('fb', callback_method_fb, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:31:21.248648Z",
     "start_time": "2020-08-06T12:31:21.226667Z"
    }
   },
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:31:21.961560Z",
     "start_time": "2020-08-06T12:31:21.952608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8017838677478259815, 4, 7), (8017838677478259815, 9, 13)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:31:59.451739Z",
     "start_time": "2020-08-06T12:31:59.447755Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"I'd say that Facebook is evil.\",\n",
       "  'ents': [{'start': 13, 'end': 29, 'label': 'MATCH'}]},\n",
       " {'text': '- Facebook is pretty cool, right?',\n",
       "  'ents': [{'start': 2, 'end': 25, 'label': 'MATCH'}]}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:33:38.354378Z",
     "start_time": "2020-08-06T12:33:38.350390Z"
    }
   },
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:33:39.874110Z",
     "start_time": "2020-08-06T12:33:39.869110Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I'd say that \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook is evil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MATCH</span>\n",
       "</mark>\n",
       ".</div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">- \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook is pretty cool\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MATCH</span>\n",
       "</mark>\n",
       ", right?</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(matched_sets, style='ent', manual=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:37:16.420685Z",
     "start_time": "2020-08-06T12:37:16.416695Z"
    }
   },
   "outputs": [],
   "source": [
    "pattern = [{\"ORTH\": \"(\"}, {\"SHAPE\": \"ddd\"}, {\"ORTH\": \")\"}, {\"SHAPE\": \"dddd\"}, {\"ORTH\":\"-\", \"OP\": \"?\"}, {\"SHAPE\": \"dddd\"},{\"ORTH\":\"-\", \"OP\": \"?\"}, {\"SHAPE\": \"dddd\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:37:16.793455Z",
     "start_time": "2020-08-06T12:37:16.780462Z"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"My phone number is (123) 1386-7945-5832, Please call me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:37:17.159335Z",
     "start_time": "2020-08-06T12:37:17.156319Z"
    }
   },
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('phone_num', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:37:18.195257Z",
     "start_time": "2020-08-06T12:37:18.192268Z"
    }
   },
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:37:22.420312Z",
     "start_time": "2020-08-06T12:37:22.416346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(534639841163226624, 4, 12)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:37:27.663344Z",
     "start_time": "2020-08-06T12:37:27.657356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'phone', 'number', 'is', '(', '123', ')', '1386', '-', '7945', '-', '5832', ',', 'Please', 'call', 'me']\n"
     ]
    }
   ],
   "source": [
    "print([t.text for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:37:36.315299Z",
     "start_time": "2020-08-06T12:37:36.311311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123) 1386-7945-5832\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Email Address Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:38:02.206371Z",
     "start_time": "2020-08-06T12:38:02.203385Z"
    }
   },
   "outputs": [],
   "source": [
    "pattern = [{\"TEXT\": {\"REGEX\": \"[a-zA-Z0-9-_.]+@[a-zA-Z0-9_.]+\"}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:38:08.824294Z",
     "start_time": "2020-08-06T12:38:08.820281Z"
    }
   },
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"email\", None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:38:09.534141Z",
     "start_time": "2020-08-06T12:38:09.524191Z"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"my email is 536480973@qq.com and 13867945832@163.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:38:19.337343Z",
     "start_time": "2020-08-06T12:38:19.334375Z"
    }
   },
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:38:19.761734Z",
     "start_time": "2020-08-06T12:38:19.757769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7320900731437023467, 3, 4), (7320900731437023467, 5, 6)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:38:21.035551Z",
     "start_time": "2020-08-06T12:38:21.031562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536480973@qq.com\n",
      "13867945832@163.com\n"
     ]
    }
   ],
   "source": [
    "for matcher_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:38:32.236731Z",
     "start_time": "2020-08-06T12:38:32.232718Z"
    }
   },
   "outputs": [],
   "source": [
    "a = \"536480973@qq.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:38:32.965512Z",
     "start_time": "2020-08-06T12:38:32.962491Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:38:34.476694Z",
     "start_time": "2020-08-06T12:38:34.473679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['536480973@qq.com']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"[\\w]+@[\\w_.]+\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoji on social media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By defaultm Spacy's tokenizer will split emoji into separate tokens. This means that you can create a pattern for one or more emoji tokens\n",
    "#### Valid hashtags usually consists of a #, plus a sequence of ASCII characters with no whitespace, making them easy to match as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:45:14.219891Z",
     "start_time": "2020-08-06T12:45:14.215902Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_emoji = [\"ü•∫\", \"ü•∫\", \"ü•∫ \"]\n",
    "neg_emoji = [\"üêª\", \"üçî\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:45:14.748234Z",
     "start_time": "2020-08-06T12:45:14.744245Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_patterns = [[{\"ORTH\": emoji}] for emoji in pos_emoji]\n",
    "neg_patterns = [[{\"ORTH\": emoji}] for emoji in neg_emoji]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:45:15.253250Z",
     "start_time": "2020-08-06T12:45:15.249256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'ORTH': '\\U0001f97a'}], [{'ORTH': '\\U0001f97a'}], [{'ORTH': '\\U0001f97a '}]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:45:17.490179Z",
     "start_time": "2020-08-06T12:45:17.485192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'ORTH': 'üêª'}], [{'ORTH': 'üçî'}]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:45:28.073769Z",
     "start_time": "2020-08-06T12:45:28.069779Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_sentiment(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    if doc.vocab.strings[match_id] == \"HAPPY\":\n",
    "        doc.sentiment += 0.1\n",
    "    elif doc.vocab.strings[match_id] == \"SAD\":\n",
    "        doc.sentiment -= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:45:33.201755Z",
     "start_time": "2020-08-06T12:45:29.723059Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:45:36.416253Z",
     "start_time": "2020-08-06T12:45:36.412264Z"
    }
   },
   "outputs": [],
   "source": [
    "matcher.add(\"HAPPY\", label_sentiment, *pos_patterns)\n",
    "matcher.add(\"SAD\", label_sentiment, *neg_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:46:44.867816Z",
     "start_time": "2020-08-06T12:46:44.863827Z"
    }
   },
   "outputs": [],
   "source": [
    "matcher.add(\"HASHTAG\", None, [{\"ORTH\": \"#\"}, {\"IS_ASCII\": True}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:46:45.907565Z",
     "start_time": "2020-08-06T12:46:45.896594Z"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"Hello World ü•∫ #KGPTalkie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:46:46.382809Z",
     "start_time": "2020-08-06T12:46:46.378843Z"
    }
   },
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:46:47.392814Z",
     "start_time": "2020-08-06T12:46:47.387852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2686646543460454932, 2, 3), (16536914698459818706, 3, 5)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:48:29.682390Z",
     "start_time": "2020-08-06T12:48:29.677404Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAPPY ü•∫\n",
      "HASHTAG #KGPTalkie\n"
     ]
    }
   ],
   "source": [
    "for matcher_id, start, end in matches:\n",
    "    string_id = doc.vocab.strings[matcher_id]\n",
    "    span = doc[start:end]\n",
    "    print(string_id, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:48:35.290097Z",
     "start_time": "2020-08-06T12:48:35.286107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n",
      "ü•∫\n",
      "#\n",
      "KGPTalkie\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient phrase matching ÊúâÊïàÁü≠ËØ≠ÂåπÈÖç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:49:40.123416Z",
     "start_time": "2020-07-29T06:49:40.119474Z"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:49:40.310617Z",
     "start_time": "2020-07-29T06:49:40.307625Z"
    }
   },
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:49:40.479618Z",
     "start_time": "2020-07-29T06:49:40.476636Z"
    }
   },
   "outputs": [],
   "source": [
    "terms = ['BARAC OBAMA', 'ANGELA MERKEL', 'WASHINGTON D.C.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:49:40.649055Z",
     "start_time": "2020-07-29T06:49:40.646062Z"
    }
   },
   "outputs": [],
   "source": [
    "pattern = [nlp.make_doc(text) for text in terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:49:40.820496Z",
     "start_time": "2020-07-29T06:49:40.815510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BARAC OBAMA, ANGELA MERKEL, WASHINGTON D.C.]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:49:59.195005Z",
     "start_time": "2020-07-29T06:49:59.191992Z"
    }
   },
   "outputs": [],
   "source": [
    "matcher.add(\"term\", None, *pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:52:10.869442Z",
     "start_time": "2020-07-29T06:52:10.857474Z"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"German Chancellor ANGELA MERKEL and US President BARAC OBAMA in WASHINGTON D.C.!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:52:11.843974Z",
     "start_time": "2020-07-29T06:52:11.840951Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "German Chancellor ANGELA MERKEL and US President BARAC OBAMA in WASHINGTON D.C.!"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:52:12.265893Z",
     "start_time": "2020-07-29T06:52:12.261906Z"
    }
   },
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:52:12.674361Z",
     "start_time": "2020-07-29T06:52:12.670367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4519742297340331040, 2, 4),\n",
       " (4519742297340331040, 7, 9),\n",
       " (4519742297340331040, 10, 12)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:52:13.233306Z",
     "start_time": "2020-07-29T06:52:13.228321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANGELA MERKEL\n",
      "BARAC OBAMA\n",
      "WASHINGTON D.C.\n"
     ]
    }
   ],
   "source": [
    "for matcher_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Ruled Based Entity Recognition Âü∫‰∫éËá™ÂÆö‰πâËßÑÂàôÁöÑÂÆû‰ΩìËØÜÂà´"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity patterns are dictionaries with two keys:\"labels\"Ôºå specifying the label to assign to the entity if the pattern is matched, and \"pattern\", the match pattern. The Entity ruler accepts two types of patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T15:50:06.885677Z",
     "start_time": "2020-08-06T15:50:03.372089Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KGP Talkie ORG\n",
      "first ORDINAL\n",
      "San Francisco GPE\n"
     ]
    }
   ],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "ruler = EntityRuler(nlp)\n",
    "\n",
    "patterns = [{\"label\": \"ORG\", \"pattern\": \"KGP Talkie\"},\n",
    "            {\"label\":\"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\":\"francisco\"}]}]\n",
    "\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "nlp.add_pipe(ruler)\n",
    "\n",
    "doc = nlp(\"KGP Talkie is opening its first big office in San Francisco.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T14:07:37.598295Z",
     "start_time": "2020-08-06T14:07:37.580314Z"
    }
   },
   "outputs": [],
   "source": [
    "# ruler.to_disk(\"./patterns.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MATCHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T13:32:48.010678Z",
     "start_time": "2020-08-06T13:32:47.430200Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google I/O\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "nlp = English()\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def add_event_ent(matcher, doc, i, matches):\n",
    "    # Get the current match and create tuple of entity label, start and end.\n",
    "    # Append entity to the doc's entity. (Don't overwrite doc.ents!)\n",
    "    match_id, start, end = matches[i]\n",
    "    entity = Span(doc, start, end, label=\"EVENT\")\n",
    "    doc.ents += (entity,)\n",
    "    print(entity.text)\n",
    "\n",
    "pattern = [{\"ORTH\": \"Google\"}, {\"ORTH\": \"I\"}, {\"ORTH\": \"/\"}, {\"ORTH\": \"O\"}]\n",
    "matcher.add(\"GoogleIO\", add_event_ent, pattern)\n",
    "doc = nlp(\"This is a text about Google I/O\")\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T13:39:57.446787Z",
     "start_time": "2020-08-06T13:39:56.649604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello False\n",
      "<br> True\n",
      "world False\n",
      "! False\n",
      "<br/> True\n",
      "This False\n",
      "is False\n",
      "a False\n",
      "test False\n",
      ". False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Token\n",
    "\n",
    "# We're using a class because the component needs to be initialised with\n",
    "# the shared vocab via the nlp object\n",
    "class BadHTMLMerger(object):\n",
    "    def __init__(self, nlp):\n",
    "        # Register a new token extension to flag bad HTML\n",
    "        Token.set_extension(\"bad_html\", default=False)\n",
    "        self.matcher = Matcher(nlp.vocab)\n",
    "        self.matcher.add(\n",
    "            \"BAD_HTML\",\n",
    "            None,\n",
    "            [{\"ORTH\": \"<\"}, {\"LOWER\": \"br\"}, {\"ORTH\": \">\"}],\n",
    "            [{\"ORTH\": \"<\"}, {\"LOWER\": \"br/\"}, {\"ORTH\": \">\"}],\n",
    "        )\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        # This method is invoked when the component is called on a Doc\n",
    "        matches = self.matcher(doc)\n",
    "        spans = []  # Collect the matched spans here\n",
    "        for match_id, start, end in matches:\n",
    "            spans.append(doc[start:end])\n",
    "        with doc.retokenize() as retokenizer:\n",
    "            for span in spans:\n",
    "                retokenizer.merge(span)\n",
    "                for token in span:\n",
    "                    token._.bad_html = True  # Mark token as bad HTML\n",
    "        return doc\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "html_merger = BadHTMLMerger(nlp)\n",
    "nlp.add_pipe(html_merger, last=True)  # Add component to the pipeline\n",
    "doc = nlp(\"Hello<br>world! <br/> This is a test.\")\n",
    "for token in doc:\n",
    "    print(token.text, token._.bad_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T13:46:20.182857Z",
     "start_time": "2020-08-06T13:46:19.541574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I'd say that \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook is evil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MATCH</span>\n",
       "</mark>\n",
       ".</div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">‚Äì \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook is pretty cool\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MATCH</span>\n",
       "</mark>\n",
       ", right?</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matched_sents = []  # Collect data of matched sentences to be visualized\n",
    "\n",
    "def collect_sents(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    span = doc[start:end]  # Matched span\n",
    "    sent = span.sent  # Sentence containing matched span\n",
    "    # Append mock entity for match in displaCy style to matched_sents\n",
    "    # get the match span by ofsetting the start and end of the span with the\n",
    "    # start and end of the sentence in the doc\n",
    "    match_ents = [{\n",
    "        \"start\": span.start_char - sent.start_char,\n",
    "        \"end\": span.end_char - sent.start_char,\n",
    "        \"label\": \"MATCH\",\n",
    "    }]\n",
    "    matched_sents.append({\"text\": sent.text, \"ents\": match_ents})\n",
    "\n",
    "pattern = [{\"LOWER\": \"facebook\"}, {\"LEMMA\": \"be\"}, {\"POS\": \"ADV\", \"OP\": \"*\"},\n",
    "           {\"POS\": \"ADJ\"}]\n",
    "matcher.add(\"FacebookIs\", collect_sents, pattern)  # add pattern\n",
    "doc = nlp(\"I'd say that Facebook is evil. ‚Äì Facebook is pretty cool, right?\")\n",
    "matches = matcher(doc)\n",
    "displacy.render(matched_sents, style=\"ent\", manual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T13:55:13.201958Z",
     "start_time": "2020-08-06T13:55:09.682351Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I'd say that \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook is evil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MATCH</span>\n",
       "</mark>\n",
       ".</div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">‚Äì \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook is pretty cool\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MATCH</span>\n",
       "</mark>\n",
       ", right?</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matched_sents = []\n",
    "\n",
    "\n",
    "def collect_sents(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    span = doc[start:end]\n",
    "    sent = span.sent\n",
    "    \n",
    "    \n",
    "    match_ents = [{\"start\": span.start_char - sent.start_char,\n",
    "                  \"end\": span.end_char - sent.end_char,\n",
    "                  \"label\": \"MATCH\",}]\n",
    "    \n",
    "    matched_sents.append({\"text\": sent.text, \"ents\": match_ents})\n",
    "    \n",
    "pattern = [{\"LOWER\": \"facebook\"}, {\"LEMMA\": \"be\"}, {\"POS\": \"ADV\", \"OP\": \"*\"}, {\"POS\": \"ADJ\"}]\n",
    "\n",
    "matcher.add(\"FacebookIs\", collect_sents, pattern)\n",
    "doc = nlp(\"I'd say that Facebook is evil. ‚Äì Facebook is pretty cool, right?\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "displacy.render(matched_sents, style=\"ent\", manual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
