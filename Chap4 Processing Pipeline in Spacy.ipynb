{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATED BY HCY 20200729"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Processing text\n",
    " ----\n",
    " When you call nlp on text, spacy will tokenize it and then call each component on the Doc, in order. It then returns the processed Doc that you can work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T06:32:34.365417Z",
     "start_time": "2020-08-01T06:32:34.362416Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T06:32:58.778665Z",
     "start_time": "2020-08-01T06:32:47.290453Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T06:32:58.872473Z",
     "start_time": "2020-08-01T06:32:58.782558Z"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"This is raw textr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T06:35:31.263787Z",
     "start_time": "2020-08-01T06:35:31.259769Z"
    }
   },
   "source": [
    "#### When processing large volumns of text, the statistical models are usually more efficient if you let them work on batches of texts.spacy's nlp.pipe methop takes an iterable of texts and yields processed Doc objects. Tthe batching id done internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T06:36:30.312157Z",
     "start_time": "2020-08-01T06:36:30.309182Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = [\"This is raw text\", \"There is lots of text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T06:36:38.167313Z",
     "start_time": "2020-08-01T06:36:38.156318Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = list(nlp.pipe(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips ofr efficient processing\n",
    "* Process the texts as a stream using nlp.pipe and buffer them in batches, instead of one-by-one. This is usually much more efficient\n",
    "\n",
    "* Only apply the pipeline components you need. Getting predictions from the model that you don't actually need adds up and becomes very inefficient at scale. To prevent this, use the disable keyword argument to disable components you don't need\n",
    "\n",
    "\n",
    "#### In this example , we are using nlp.pipe to process a (potentially very large) iterable of texts as a straem. Because we are only accessing the named entitied in doc.ents(set by ner component), we'll disable all other statistical components(the tagger and parser) during processing. nlp.pipe yields Doc objects, so we can iterate over them and access the named entity predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T06:47:42.445837Z",
     "start_time": "2020-08-01T06:47:41.946187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('$9.4 million', 394, 'MONEY'), ('the prior year', 391, 'DATE'), ('$2.7 million dollars', 394, 'MONEY')]\n",
      "\n",
      "[('twelve billion dollars', 394, 'MONEY'), ('1b', 394, 'MONEY')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "texts = [\"Net income was $9.4 million compared to the prior year of $2.7 million dollars\",\n",
    "         \"Revenue exceeded twelve billion dollars, with a loss of $1b\",]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "for doc in nlp.pipe(texts, disable=[\"tagger\", \"parser\"]):\n",
    "    print([(ent.text, ent.label, ent.label_) for ent in doc.ents])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T09:11:12.688306Z",
     "start_time": "2020-08-01T09:11:12.683319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x226804660b8>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x226fe178348>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x226fe1788e8>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T09:32:24.912265Z",
     "start_time": "2020-08-01T09:32:24.907304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Revenue exceeded twelve billion dollars, with a loss of $1b"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T09:33:52.353169Z",
     "start_time": "2020-08-01T09:33:52.349180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object at 0x0000022681E28E58>\n"
     ]
    }
   ],
   "source": [
    "print(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
